{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "BreakHis_VGG16_6_Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/146790g/BreakHis-VGG16/blob/master/BreakHis_VGG16_6_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aos1i1OBdV3W"
      },
      "source": [
        "# 深層学習 VGG16モデルを用いた乳がん染色画像（BreakHis）の解析\n",
        "#（その６ : 特徴量に基づくロジステック回帰モデルによる分類 ）\n",
        "# Deep Learning for Magnification Independent Breast Cancer Histopathology\n",
        "\n",
        "<br>\n",
        "\n",
        "# Logistic Regression Classification Based on Principal Components of Feature Data which was extracted by VGG16 Model\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "<h2>対象データは、こちらをクリック ☞　</>\n",
        "<a href='https://www.kaggle.com/ambarish/breakhis'>Kaggle BreakHis Data</a>\n",
        "\n",
        "４つのMagnification levelのデータをすべて合算して、解析する\n",
        "\n",
        "<br>\n",
        "\n",
        "## 4 Magnification Levels: ×40, ×100, ×200, ×400\n",
        "\n",
        "\n",
        "During analysis and annotation, pathologists starts by identifying ROIs in\n",
        "the lowest magnification level slide (×40), then dives deeper in the latter using higher magnification levels (×100, ×200) until having a profound insight\n",
        "(×400). \n",
        "\n",
        "<br>\n",
        "\n",
        "## データ数 の概要\n",
        "\n",
        "・Training Data: 5026 images <br>\n",
        "  -- Benign Data: 1472 images <br>\n",
        "  -- Mallignant Data: 3554 images \n",
        "\n",
        "・Validation Data: 2904 images <br>\n",
        "  -- Benign Data: 1008 images <br>\n",
        "  -- Mallignant Data:1896 images <br>\n",
        "\n",
        "## Data Set Details by Magnification levels.\n",
        "\n",
        " ×40 : <br>\n",
        "×100 : <br>\n",
        "×200 : <br>\n",
        "×400 : <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjZpD7wcfTPA"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIVAoJRwTq1x",
        "outputId": "16af4809-6950-4071-b382-34e5c37f84f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pwd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjdqpKr_VU7-",
        "outputId": "4bf79918-204e-4bad-979c-ff860cbf2434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!ls -lh '/content/gdrive/My Drive/Colab Notebooks/BreakHis/data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8.0K\n",
            "drwx------ 2 root root 4.0K Jul 21 03:42 train\n",
            "drwx------ 2 root root 4.0K Jul 27 01:49 validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM4Bw3tFdESi"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_wine\n",
        "from sklearn.cluster import MeanShift, KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import mixture\n",
        "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "from scipy import interp\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#sklearn \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlxAzC96Ztzt"
      },
      "source": [
        "# 第８章 特徴データに基づくロジスティック回帰モデルによる分類　\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUF0kdiS8RhZ"
      },
      "source": [
        "### 特徴量データを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMFeHWA64J1v",
        "outputId": "1f011712-9f5c-4e05-fe36-c23d2b78a38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "train_data_dir = '/content/gdrive/My Drive/Colab Notebooks/BreakHis/data/train' # 訓練データのフォルダー\n",
        "validation_data_dir = '/content/gdrive/My Drive/Colab Notebooks/BreakHis/data/validation' # テストデータのフォルダー\n",
        "result_dir = '/content/gdrive/My Drive/Colab Notebooks/BreakHis/results'        # VGG19の出力結果を保存するフォルダー\n",
        "test_dir = '/content/gdrive/My Drive/Colab Notebooks/BreakHis/test'\n",
        "    \n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "result_dir = '/content/gdrive/My Drive/Colab Notebooks/BreakHis/results'        # VGG16の出力結果を保存するフォルダー\n",
        "\n",
        "\n",
        "with open(os.path.join(result_dir,'vgg16feature.pickle'),'rb') as web:\n",
        "  X=pickle.load(web)\n",
        "\n",
        "\n",
        "\n",
        "l1 = [0] * 78\n",
        "l2= [1]*94\n",
        "label=l1+l2\n",
        "\n",
        "y=np.array(label)\n",
        "\n",
        "print(len(y))\n",
        "print(X.shape)\n",
        "\n",
        "X.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172\n",
            "(172, 256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.433194</td>\n",
              "      <td>0.237343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.551462</td>\n",
              "      <td>1.584471</td>\n",
              "      <td>0.625109</td>\n",
              "      <td>0.479136</td>\n",
              "      <td>0.020791</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.102332</td>\n",
              "      <td>0.188140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.396689</td>\n",
              "      <td>1.844249</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026968</td>\n",
              "      <td>0.565343</td>\n",
              "      <td>1.454684</td>\n",
              "      <td>0.431100</td>\n",
              "      <td>0.290944</td>\n",
              "      <td>0.215467</td>\n",
              "      <td>0.952217</td>\n",
              "      <td>1.556580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111209</td>\n",
              "      <td>0.158797</td>\n",
              "      <td>0.163824</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05042</td>\n",
              "      <td>1.436597</td>\n",
              "      <td>0.528508</td>\n",
              "      <td>0.026793</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.105006</td>\n",
              "      <td>0.577345</td>\n",
              "      <td>2.113621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.309258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076591</td>\n",
              "      <td>1.589648</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.105026</td>\n",
              "      <td>0.235231</td>\n",
              "      <td>1.247267</td>\n",
              "      <td>0.146883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.960971</td>\n",
              "      <td>0.072056</td>\n",
              "      <td>1.595739</td>\n",
              "      <td>0.214662</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206624</td>\n",
              "      <td>1.873543</td>\n",
              "      <td>0.568496</td>\n",
              "      <td>0.428319</td>\n",
              "      <td>1.357321</td>\n",
              "      <td>2.048620</td>\n",
              "      <td>0.124101</td>\n",
              "      <td>0.433003</td>\n",
              "      <td>0.365921</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.009185</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.689157</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.830676</td>\n",
              "      <td>0.789047</td>\n",
              "      <td>0.784227</td>\n",
              "      <td>0.083634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.306518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.585309</td>\n",
              "      <td>0.338991</td>\n",
              "      <td>0.572953</td>\n",
              "      <td>0.54383</td>\n",
              "      <td>0.877386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.434742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.328300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.054899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.716150</td>\n",
              "      <td>0.826995</td>\n",
              "      <td>1.195088</td>\n",
              "      <td>0.241468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.987432</td>\n",
              "      <td>0.415407</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.649006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.418885</td>\n",
              "      <td>0.007660</td>\n",
              "      <td>0.090456</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.321693</td>\n",
              "      <td>0.686597</td>\n",
              "      <td>0.626664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.869008</td>\n",
              "      <td>1.437314</td>\n",
              "      <td>0.235521</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.201078</td>\n",
              "      <td>1.047137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.537235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541292</td>\n",
              "      <td>0.171941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.724426</td>\n",
              "      <td>0.206602</td>\n",
              "      <td>0.902463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.162006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.684559</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.948754</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.613472</td>\n",
              "      <td>1.218000</td>\n",
              "      <td>0.280792</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.289563</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.736669</td>\n",
              "      <td>0.107959</td>\n",
              "      <td>0.141006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.671071</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.610026</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.566219</td>\n",
              "      <td>0.405849</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.326723</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.418382</td>\n",
              "      <td>0.611495</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.428842</td>\n",
              "      <td>0.405021</td>\n",
              "      <td>0.390679</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377403</td>\n",
              "      <td>0.152265</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.320356</td>\n",
              "      <td>0.636156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.075839</td>\n",
              "      <td>0.422961</td>\n",
              "      <td>0.153457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.532768</td>\n",
              "      <td>0.420679</td>\n",
              "      <td>0.647546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.465920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.180141</td>\n",
              "      <td>1.283007</td>\n",
              "      <td>0.312222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.481541</td>\n",
              "      <td>0.420336</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.872057</td>\n",
              "      <td>0.472561</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123560</td>\n",
              "      <td>0.772115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.328423</td>\n",
              "      <td>0.842926</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.136258</td>\n",
              "      <td>0.472292</td>\n",
              "      <td>0.786054</td>\n",
              "      <td>0.613113</td>\n",
              "      <td>0.335140</td>\n",
              "      <td>0.194091</td>\n",
              "      <td>0.505944</td>\n",
              "      <td>0.175480</td>\n",
              "      <td>0.643338</td>\n",
              "      <td>0.717072</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.583612</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.263637</td>\n",
              "      <td>0.889500</td>\n",
              "      <td>0.909541</td>\n",
              "      <td>0.600619</td>\n",
              "      <td>0.199971</td>\n",
              "      <td>0.882761</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.622806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781961</td>\n",
              "      <td>0.526079</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.724968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353456</td>\n",
              "      <td>0.292023</td>\n",
              "      <td>1.017933</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.255840</td>\n",
              "      <td>0.708143</td>\n",
              "      <td>0.895666</td>\n",
              "      <td>0.658374</td>\n",
              "      <td>0.074447</td>\n",
              "      <td>0.746882</td>\n",
              "      <td>0.245530</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.151092</td>\n",
              "      <td>0.578391</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.431055</td>\n",
              "      <td>0.715218</td>\n",
              "      <td>0.501422</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.870980</td>\n",
              "      <td>0.836086</td>\n",
              "      <td>0.579863</td>\n",
              "      <td>0.890332</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.619595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.597802</td>\n",
              "      <td>0.461703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.790383</td>\n",
              "      <td>1.056592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000560</td>\n",
              "      <td>0.464419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.661468</td>\n",
              "      <td>0.831154</td>\n",
              "      <td>0.454522</td>\n",
              "      <td>0.954082</td>\n",
              "      <td>0.706323</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.118271</td>\n",
              "      <td>0.684017</td>\n",
              "      <td>1.139560</td>\n",
              "      <td>0.733019</td>\n",
              "      <td>0.774769</td>\n",
              "      <td>0.544980</td>\n",
              "      <td>0.942081</td>\n",
              "      <td>0.922542</td>\n",
              "      <td>0.755323</td>\n",
              "      <td>0.765121</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.096608</td>\n",
              "      <td>1.394846</td>\n",
              "      <td>0.527889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.469433</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.012401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.336541</td>\n",
              "      <td>1.015579</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.284347</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.410253</td>\n",
              "      <td>1.282213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.194283</td>\n",
              "      <td>0.747365</td>\n",
              "      <td>0.638556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.643979</td>\n",
              "      <td>1.310159</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625270</td>\n",
              "      <td>0.838343</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.589039</td>\n",
              "      <td>1.291207</td>\n",
              "      <td>1.415172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.947611</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.313818</td>\n",
              "      <td>0.587444</td>\n",
              "      <td>0.929679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.157831</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.435006</td>\n",
              "      <td>1.183660</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.044837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.050298</td>\n",
              "      <td>1.385072</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.485798</td>\n",
              "      <td>1.076328</td>\n",
              "      <td>0.089373</td>\n",
              "      <td>1.485117</td>\n",
              "      <td>1.599277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.883193</td>\n",
              "      <td>1.501190</td>\n",
              "      <td>1.697194</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 256 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1    2         3    ...       252       253       254  255\n",
              "0  1.433194  0.237343  0.0  0.000000  ...  0.124101  0.433003  0.365921  0.0\n",
              "1  1.009185  0.000000  0.0  0.689157  ...  0.280792  0.000000  0.000000  0.0\n",
              "2  0.289563  0.000000  0.0  0.000000  ...  0.175480  0.643338  0.717072  0.0\n",
              "3  0.583612  0.000000  0.0  0.263637  ...  0.922542  0.755323  0.765121  0.0\n",
              "4  0.000000  0.000000  0.0  0.096608  ...  0.883193  1.501190  1.697194  0.0\n",
              "\n",
              "[5 rows x 256 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NePTrIHIDsS5",
        "outputId": "c72c55bf-c385-4c8d-e5ae-990b7943b20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    stratify=y,\n",
        "                                                    test_size=0.20)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(137, 256)\n",
            "(137,)\n",
            "(35, 256)\n",
            "(35,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOU6DJfodChy"
      },
      "source": [
        "## データを正規化して、主成分分析を行い、その主成分に基づいてロジスティック回帰モデルによる分類を行う\n",
        "## 主成分は、第１主成分から第5主成分までを算出して、それらに基づいてロジスティック回帰モデルを適用する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLmHZXicFNG",
        "outputId": "036b816d-712a-4279-cb5b-67f3659d59ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#logistic Regression\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipe_lr = make_pipeline(StandardScaler(),\n",
        "                        PCA(n_components=5),\n",
        "                        LogisticRegression(random_state=1))\n",
        "\n",
        "\n",
        "pipe_lr.fit(X_train, y_train)\n",
        "y_pred = pipe_lr.predict(X_test)\n",
        "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCqkK616YOQE"
      },
      "source": [
        "## Accuracyは、91.4%であった。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arnSFHlmdOdC"
      },
      "source": [
        "## 混合行列を作成する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPjmlWdgcUaj",
        "outputId": "132bb622-e86c-41c5-def3-7f201212f643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = pipe_lr.predict(X_test)\n",
        "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "print(confmat)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(confmat.shape[0]):\n",
        "    for j in range(confmat.shape[1]):\n",
        "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center',fontsize=30)\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14  2]\n",
            " [ 1 18]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh5s8NaNV6UN"
      },
      "source": [
        "## Accuracy : 91.4%\n",
        "## Recall: 94.7%\n",
        "## F1 : 92.3 %\n",
        "\n",
        "# Accuracy : 乳癌の患者を正しく乳癌と判定し、かつ、正常の患者を正常と正しく判定できる確率\n",
        "# Recall: 乳癌の患者を正しく乳癌と判定できる確率\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etbdR3fxKTiL",
        "outputId": "3780fee1-b2c0-4770-b10d-c0a71f7236de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "print('Accuracy: %.3f' % accuracy_score(y_true=y_test, y_pred=y_pred))\n",
        "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
        "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.914\n",
            "Recall: 0.947\n",
            "F1: 0.923\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}